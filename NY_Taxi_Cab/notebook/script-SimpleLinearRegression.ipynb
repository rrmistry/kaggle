{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b636e22977c7364a057d29195216501485c041a7"
   },
   "source": [
    "Rohit's First Kernal - NYC Taxi Fare Prediction\n",
    "===========\n",
    "This is the first kernal for submission for Google Cloud Playground [New York City Taxi Fare Prediction](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction)\n",
    "\n",
    "Strategy\n",
    "--------------------\n",
    "1. Filter out outliers\n",
    "    1. Remove data outside NYC\n",
    "    2. Remove data where fare is unresonable (too high / too low)\n",
    "2. Use Linear Regression ML Model On Clean Data\n",
    "3. Use Linear Fit On Unclean Data\n",
    "\n",
    "Using NYC Open Data\n",
    "-------------------\n",
    "NYC Open Data is stored in Google Big Query open datasets. To access this data in your notebook, check out kernal [How to Query the NYC Open Data\n",
    "](https://www.kaggle.com/paultimothymooney/how-to-query-the-nyc-open-data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to plot 3d scatter plots\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import math\n",
    "\n",
    "# to print out current time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import traceback\n",
    "\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "e78d5459cdfa29acfe87fc6282a41cc90bae2128"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "\n",
    "# Try to load the data. This may be an intensive process\n",
    "df_train = pd.read_csv(r'M:\\kaggle\\NY Taxi Cab\\input\\train.csv', nrows = 10000, parse_dates=[\"pickup_datetime\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-06-15 17:26:21.0000001</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-06-15 17:26:21</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05 16:52:16.0000002</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2010-01-05 16:52:16</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-18 00:35:00.00000049</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2011-08-18 00:35:00</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-21 04:30:42.0000001</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2012-04-21 04:30:42</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-09 07:51:00.000000135</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2010-03-09 07:51:00</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-01-06 09:50:45.0000002</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2011-01-06 09:50:45</td>\n",
       "      <td>-74.000964</td>\n",
       "      <td>40.731630</td>\n",
       "      <td>-73.972892</td>\n",
       "      <td>40.758233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012-11-20 20:35:00.0000001</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2012-11-20 20:35:00</td>\n",
       "      <td>-73.980002</td>\n",
       "      <td>40.751662</td>\n",
       "      <td>-73.973802</td>\n",
       "      <td>40.764842</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012-01-04 17:22:00.00000081</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2012-01-04 17:22:00</td>\n",
       "      <td>-73.951300</td>\n",
       "      <td>40.774138</td>\n",
       "      <td>-73.990095</td>\n",
       "      <td>40.751048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012-12-03 13:10:00.000000125</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2012-12-03 13:10:00</td>\n",
       "      <td>-74.006462</td>\n",
       "      <td>40.726713</td>\n",
       "      <td>-73.993078</td>\n",
       "      <td>40.731628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009-09-02 01:11:00.00000083</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2009-09-02 01:11:00</td>\n",
       "      <td>-73.980658</td>\n",
       "      <td>40.733873</td>\n",
       "      <td>-73.991540</td>\n",
       "      <td>40.758138</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             key  fare_amount     pickup_datetime  \\\n",
       "0    2009-06-15 17:26:21.0000001          4.5 2009-06-15 17:26:21   \n",
       "1    2010-01-05 16:52:16.0000002         16.9 2010-01-05 16:52:16   \n",
       "2   2011-08-18 00:35:00.00000049          5.7 2011-08-18 00:35:00   \n",
       "3    2012-04-21 04:30:42.0000001          7.7 2012-04-21 04:30:42   \n",
       "4  2010-03-09 07:51:00.000000135          5.3 2010-03-09 07:51:00   \n",
       "5    2011-01-06 09:50:45.0000002         12.1 2011-01-06 09:50:45   \n",
       "6    2012-11-20 20:35:00.0000001          7.5 2012-11-20 20:35:00   \n",
       "7   2012-01-04 17:22:00.00000081         16.5 2012-01-04 17:22:00   \n",
       "8  2012-12-03 13:10:00.000000125          9.0 2012-12-03 13:10:00   \n",
       "9   2009-09-02 01:11:00.00000083          8.9 2009-09-02 01:11:00   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.844311        40.721319         -73.841610         40.712278   \n",
       "1        -74.016048        40.711303         -73.979268         40.782004   \n",
       "2        -73.982738        40.761270         -73.991242         40.750562   \n",
       "3        -73.987130        40.733143         -73.991567         40.758092   \n",
       "4        -73.968095        40.768008         -73.956655         40.783762   \n",
       "5        -74.000964        40.731630         -73.972892         40.758233   \n",
       "6        -73.980002        40.751662         -73.973802         40.764842   \n",
       "7        -73.951300        40.774138         -73.990095         40.751048   \n",
       "8        -74.006462        40.726713         -73.993078         40.731628   \n",
       "9        -73.980658        40.733873         -73.991540         40.758138   \n",
       "\n",
       "   passenger_count  \n",
       "0                1  \n",
       "1                1  \n",
       "2                2  \n",
       "3                1  \n",
       "4                1  \n",
       "5                1  \n",
       "6                1  \n",
       "7                1  \n",
       "8                1  \n",
       "9                2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>512.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>512.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.608164</td>\n",
       "      <td>-72.242612</td>\n",
       "      <td>39.795867</td>\n",
       "      <td>-72.385201</td>\n",
       "      <td>39.876019</td>\n",
       "      <td>1.632812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.315499</td>\n",
       "      <td>11.202770</td>\n",
       "      <td>6.171227</td>\n",
       "      <td>10.736289</td>\n",
       "      <td>5.914530</td>\n",
       "      <td>1.270598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>-74.035839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-74.035839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>-73.992777</td>\n",
       "      <td>40.735444</td>\n",
       "      <td>-73.993028</td>\n",
       "      <td>40.731372</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>-73.982185</td>\n",
       "      <td>40.752074</td>\n",
       "      <td>-73.980713</td>\n",
       "      <td>40.752815</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>-73.968465</td>\n",
       "      <td>40.766767</td>\n",
       "      <td>-73.964584</td>\n",
       "      <td>40.767634</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.828531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.881878</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "count   512.000000        512.000000       512.000000         512.000000   \n",
       "mean     11.608164        -72.242612        39.795867         -72.385201   \n",
       "std       9.315499         11.202770         6.171227          10.736289   \n",
       "min       2.500000        -74.035839         0.000000         -74.035839   \n",
       "25%       6.000000        -73.992777        40.735444         -73.993028   \n",
       "50%       8.500000        -73.982185        40.752074         -73.980713   \n",
       "75%      13.000000        -73.968465        40.766767         -73.964584   \n",
       "max      58.000000          0.000000        40.828531           0.000000   \n",
       "\n",
       "       dropoff_latitude  passenger_count  \n",
       "count        512.000000       512.000000  \n",
       "mean          39.876019         1.632812  \n",
       "std            5.914530         1.270598  \n",
       "min            0.000000         0.000000  \n",
       "25%           40.731372         1.000000  \n",
       "50%           40.752815         1.000000  \n",
       "75%           40.767634         2.000000  \n",
       "max           40.881878         6.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMNS = ['key',\n",
    "               'fare_amount',\n",
    "               'pickup_datetime',\n",
    "               'pickup_longitude',\n",
    "               'pickup_latitude',\n",
    "               'dropoff_longitude',\n",
    "               'dropoff_latitude',\n",
    "               'passenger_count']\n",
    "\n",
    "LABEL_COLUMN = 'fare_amount' # 'pickup_datetime' #\n",
    "\n",
    "DEFAULTS = [['NoKey'],\n",
    "            [0.0],\n",
    "            ['BadDate'],\n",
    "            [-74.0],\n",
    "            [40.0],\n",
    "            [-74.0],\n",
    "            [40.7],\n",
    "            [1.0]]\n",
    "\n",
    "TRAIN_TEST_SPLIT_RATIO = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filenames, mode, batch_size = BATCH_SIZE):\n",
    "        \n",
    "    def _input_fn():\n",
    "        \n",
    "        def parse_dataset(filename, header_lines = 1):\n",
    "            return tf.data.TextLineDataset(filenames=filename).skip(header_lines) \n",
    "        \n",
    "        def parse_batch(value_column):\n",
    "            if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "                columns = tf.decode_csv(value_column, record_defaults = DEFAULTS[:1] + DEFAULTS[1:])\n",
    "                features = dict(zip(CSV_COLUMNS[:1] + CSV_COLUMNS[1:], columns))\n",
    "                label = DEFAULTS[1]\n",
    "            else:\n",
    "                columns = tf.decode_csv(value_column, record_defaults = DEFAULTS)\n",
    "                features = dict(zip(CSV_COLUMNS, columns))\n",
    "                label = features.pop(LABEL_COLUMN)\n",
    "            return features, label\n",
    "\n",
    "        # Create list of file names that match \"glob\" pattern (i.e. data_file_*.csv)\n",
    "        filenames_dataset = tf.data.Dataset.list_files(filenames)\n",
    "        \n",
    "        # Read lines from text files\n",
    "        dataset = filenames_dataset.flat_map(parse_dataset)\n",
    "        \n",
    "        # Parse text lines as comma-separated values (CSV)\n",
    "        dataset = dataset.map(parse_batch)\n",
    "        \n",
    "        # Note:\n",
    "        # use tf.data.Dataset.flat_map to apply one to many transformations (here: filename -> text lines)\n",
    "        # use tf.data.Dataset.map            to apply one to one    transformations (here: text line -> feature list)\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                num_epochs = None # loop indefinitely\n",
    "                dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "        else:\n",
    "                num_epochs = 1 # end-of-input after this\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "        \n",
    "        # Skip header row\n",
    "        return dataset.skip(1).make_one_shot_iterator().get_next()\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train():\n",
    "    return read_dataset('../input/train/train-*.csv', mode = tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "def get_valid():\n",
    "    return read_dataset('../input/train/test-*.csv', mode = tf.estimator.ModeKeys.EVAL)\n",
    "\n",
    "def get_test():\n",
    "    return read_dataset('../input/test.csv', mode = tf.estimator.ModeKeys.PREDICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_COLUMNS = [\n",
    "    tf.feature_column.numeric_column('pickup_longitude'),\n",
    "    tf.feature_column.numeric_column('pickup_latitude'),\n",
    "    tf.feature_column.numeric_column('dropoff_longitude'),\n",
    "    tf.feature_column.numeric_column('dropoff_latitude'),\n",
    "    tf.feature_column.numeric_column('passenger_count'),\n",
    "]\n",
    "\n",
    "def add_more_features(feats):\n",
    "    # Nothing to add (yet!)\n",
    "    return feats\n",
    "\n",
    "feature_cols = add_more_features(INPUT_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rmse(model, name, input_fn):\n",
    "    metrics = model.evaluate(input_fn = input_fn, steps = None)\n",
    "    print('RMSE on {} dataset = {}'.format(name, np.sqrt(metrics['average_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../taxi_trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002A50AEDCBA8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "Begin Training ----------------  2018-09-11 19:59:58.138549\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ../taxi_trained\\model.ckpt.\n",
      "INFO:tensorflow:loss = 112885.22, step = 0\n",
      "INFO:tensorflow:global_step/sec: 29.0939\n",
      "INFO:tensorflow:loss = 45621.688, step = 100 (3.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.7603\n",
      "INFO:tensorflow:loss = 47899.18, step = 200 (3.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.1205\n",
      "INFO:tensorflow:loss = 42463.574, step = 300 (3.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.3582\n",
      "INFO:tensorflow:loss = 46683.79, step = 400 (3.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5811\n",
      "INFO:tensorflow:loss = 53198.418, step = 500 (3.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5903\n",
      "INFO:tensorflow:loss = 51196.81, step = 600 (3.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.7685\n",
      "INFO:tensorflow:loss = 46803.883, step = 700 (3.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4136\n",
      "INFO:tensorflow:loss = 62571.797, step = 800 (3.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.6466\n",
      "INFO:tensorflow:loss = 60568.855, step = 900 (3.264 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ../taxi_trained\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 46243.746.\n",
      "Begin Testing ----------------  2018-09-11 20:00:34.097565\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-12-00:00:34\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../taxi_trained\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-12-00:00:46\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 100.13268, global_step = 1000, label/mean = 11.376159, loss = 51218.38, prediction/mean = 10.83314\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: ../taxi_trained\\model.ckpt-1000\n",
      "RMSE on validation dataset = 10.006631851196289\n",
      "Finished Testing ----------------  2018-09-11 20:00:46.789559\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = '../taxi_trained'\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "        \n",
    "        model = tf.estimator.LinearRegressor(feature_columns = feature_cols, model_dir = OUTDIR)\n",
    "        \n",
    "        print('Begin Training ---------------- ', datetime.datetime.now())\n",
    "        model.train(input_fn = get_train(), steps = 1000)\n",
    "        \n",
    "        print('Begin Testing ---------------- ', datetime.datetime.now())        \n",
    "        print_rmse(model, 'validation', get_valid())\n",
    "        \n",
    "        print('Finished Testing ---------------- ', datetime.datetime.now())   \n",
    "    except:\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE on validation dataset = 10.006631851196289"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
