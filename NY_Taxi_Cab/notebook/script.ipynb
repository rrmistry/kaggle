{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b636e22977c7364a057d29195216501485c041a7"
   },
   "source": [
    "Rohit's First Kernal - NYC Taxi Fare Prediction\n",
    "===========\n",
    "This is the first kernal for submission for Google Cloud Playground [New York City Taxi Fare Prediction](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction)\n",
    "\n",
    "Strategy\n",
    "--------------------\n",
    "1. Filter out outliers\n",
    "    1. Remove data outside NYC\n",
    "    2. Remove data where fare is unresonable (too high / too low)\n",
    "2. Use Linear Regression ML Model On Clean Data\n",
    "3. Use Linear Fit On Unclean Data\n",
    "\n",
    "Using NYC Open Data\n",
    "-------------------\n",
    "NYC Open Data is stored in Google Big Query open datasets. To access this data in your notebook, check out kernal [How to Query the NYC Open Data\n",
    "](https://www.kaggle.com/paultimothymooney/how-to-query-the-nyc-open-data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to plot 3d scatter plots\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import math\n",
    "\n",
    "# to print out current time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import traceback\n",
    "\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read exploratory dataset into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "e78d5459cdfa29acfe87fc6282a41cc90bae2128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started reading dataset -------------  2018-09-15 22:51:20.085878\n",
      "Finished reading dataset -------------  2018-09-15 22:51:20.281872\n"
     ]
    }
   ],
   "source": [
    "# BASE_PATH = os.path.dirname(\"__file__\")\n",
    "BASE_PATH = r'M:/kaggle/NY Taxi Cab/notebook/'\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "print('Started reading dataset ------------- ', datetime.datetime.now())\n",
    "\n",
    "# Try to load the data. This may be an intensive process\n",
    "df_train = pd.read_csv(os.path.join(BASE_PATH, r'..\\input\\train_split\\train-000000000003.csv'), nrows=BATCH_SIZE*2, parse_dates=[\"pickup_datetime\"]);\n",
    "\n",
    "print('Finished reading dataset ------------- ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe some dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>key_original</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hourofday</th>\n",
       "      <th>pickuplon</th>\n",
       "      <th>pickuplat</th>\n",
       "      <th>dropofflon</th>\n",
       "      <th>dropofflat</th>\n",
       "      <th>passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-09-25 00:48:44+00-73.98575140.732774-73.9...</td>\n",
       "      <td>2009-09-25 00:48:44 UTC</td>\n",
       "      <td>56.61</td>\n",
       "      <td>2009-09-25 00:48:44</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.985751</td>\n",
       "      <td>40.732774</td>\n",
       "      <td>-73.916322</td>\n",
       "      <td>40.560941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-06-21 00:47:00+00-73.95714840.717472-73.9...</td>\n",
       "      <td>2013-06-21 00:47:00 UTC</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2013-06-21 00:47:00</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.957148</td>\n",
       "      <td>40.717472</td>\n",
       "      <td>-73.960302</td>\n",
       "      <td>40.696392</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-08 00:49:08+00-73.95177459716796940.77...</td>\n",
       "      <td>2015-05-08 00:49:08 UTC</td>\n",
       "      <td>10.50</td>\n",
       "      <td>2015-05-08 00:49:08</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.951775</td>\n",
       "      <td>40.777752</td>\n",
       "      <td>-73.980659</td>\n",
       "      <td>40.737827</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-12-24 00:45:35+00-74.00531640.728795-74.0...</td>\n",
       "      <td>2010-12-24 00:45:35 UTC</td>\n",
       "      <td>6.90</td>\n",
       "      <td>2010-12-24 00:45:35</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>-74.005316</td>\n",
       "      <td>40.728795</td>\n",
       "      <td>-74.004893</td>\n",
       "      <td>40.748165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-11-08 00:26:59+00-73.9420140.79534-73.945...</td>\n",
       "      <td>2013-11-08 00:26:59 UTC</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2013-11-08 00:26:59</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.942010</td>\n",
       "      <td>40.795340</td>\n",
       "      <td>-73.945941</td>\n",
       "      <td>40.814598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-07-26 00:51:00+00-73.9816940.751112-73.99...</td>\n",
       "      <td>2013-07-26 00:51:00 UTC</td>\n",
       "      <td>10.50</td>\n",
       "      <td>2013-07-26 00:51:00</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.981690</td>\n",
       "      <td>40.751112</td>\n",
       "      <td>-73.997617</td>\n",
       "      <td>40.720812</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-11-19 00:36:00+00-73.99061340.750782-73.9...</td>\n",
       "      <td>2010-11-19 00:36:00 UTC</td>\n",
       "      <td>7.70</td>\n",
       "      <td>2010-11-19 00:36:00</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990613</td>\n",
       "      <td>40.750782</td>\n",
       "      <td>-73.978248</td>\n",
       "      <td>40.748900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011-12-30 00:30:00+00-73.98829840.72796-73.92...</td>\n",
       "      <td>2011-12-30 00:30:00 UTC</td>\n",
       "      <td>26.10</td>\n",
       "      <td>2011-12-30 00:30:00</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.988298</td>\n",
       "      <td>40.727960</td>\n",
       "      <td>-73.921317</td>\n",
       "      <td>40.867857</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012-12-14 00:11:38+00-73.97705840.752328-73.9...</td>\n",
       "      <td>2012-12-14 00:11:38 UTC</td>\n",
       "      <td>12.50</td>\n",
       "      <td>2012-12-14 00:11:38</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.977058</td>\n",
       "      <td>40.752328</td>\n",
       "      <td>-73.979702</td>\n",
       "      <td>40.782815</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-05-21 00:49:01+00-74.00522940.728762-73.9...</td>\n",
       "      <td>2010-05-21 00:49:01 UTC</td>\n",
       "      <td>8.90</td>\n",
       "      <td>2010-05-21 00:49:01</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>-74.005229</td>\n",
       "      <td>40.728762</td>\n",
       "      <td>-73.977420</td>\n",
       "      <td>40.749979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 key             key_original  \\\n",
       "0  2009-09-25 00:48:44+00-73.98575140.732774-73.9...  2009-09-25 00:48:44 UTC   \n",
       "1  2013-06-21 00:47:00+00-73.95714840.717472-73.9...  2013-06-21 00:47:00 UTC   \n",
       "2  2015-05-08 00:49:08+00-73.95177459716796940.77...  2015-05-08 00:49:08 UTC   \n",
       "3  2010-12-24 00:45:35+00-74.00531640.728795-74.0...  2010-12-24 00:45:35 UTC   \n",
       "4  2013-11-08 00:26:59+00-73.9420140.79534-73.945...  2013-11-08 00:26:59 UTC   \n",
       "5  2013-07-26 00:51:00+00-73.9816940.751112-73.99...  2013-07-26 00:51:00 UTC   \n",
       "6  2010-11-19 00:36:00+00-73.99061340.750782-73.9...  2010-11-19 00:36:00 UTC   \n",
       "7  2011-12-30 00:30:00+00-73.98829840.72796-73.92...  2011-12-30 00:30:00 UTC   \n",
       "8  2012-12-14 00:11:38+00-73.97705840.752328-73.9...  2012-12-14 00:11:38 UTC   \n",
       "9  2010-05-21 00:49:01+00-74.00522940.728762-73.9...  2010-05-21 00:49:01 UTC   \n",
       "\n",
       "   fare_amount     pickup_datetime dayofweek  hourofday  pickuplon  pickuplat  \\\n",
       "0        56.61 2009-09-25 00:48:44       Fri          0 -73.985751  40.732774   \n",
       "1        11.00 2013-06-21 00:47:00       Fri          0 -73.957148  40.717472   \n",
       "2        10.50 2015-05-08 00:49:08       Fri          0 -73.951775  40.777752   \n",
       "3         6.90 2010-12-24 00:45:35       Fri          0 -74.005316  40.728795   \n",
       "4         7.50 2013-11-08 00:26:59       Fri          0 -73.942010  40.795340   \n",
       "5        10.50 2013-07-26 00:51:00       Fri          0 -73.981690  40.751112   \n",
       "6         7.70 2010-11-19 00:36:00       Fri          0 -73.990613  40.750782   \n",
       "7        26.10 2011-12-30 00:30:00       Fri          0 -73.988298  40.727960   \n",
       "8        12.50 2012-12-14 00:11:38       Fri          0 -73.977058  40.752328   \n",
       "9         8.90 2010-05-21 00:49:01       Fri          0 -74.005229  40.728762   \n",
       "\n",
       "   dropofflon  dropofflat  passengers  \n",
       "0  -73.916322   40.560941           1  \n",
       "1  -73.960302   40.696392           1  \n",
       "2  -73.980659   40.737827           2  \n",
       "3  -74.004893   40.748165           1  \n",
       "4  -73.945941   40.814598           1  \n",
       "5  -73.997617   40.720812           5  \n",
       "6  -73.978248   40.748900           2  \n",
       "7  -73.921317   40.867857           2  \n",
       "8  -73.979702   40.782815           1  \n",
       "9  -73.977420   40.749979           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>hourofday</th>\n",
       "      <th>pickuplon</th>\n",
       "      <th>pickuplat</th>\n",
       "      <th>dropofflon</th>\n",
       "      <th>dropofflat</th>\n",
       "      <th>passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.642822</td>\n",
       "      <td>0.440430</td>\n",
       "      <td>-73.981624</td>\n",
       "      <td>40.745231</td>\n",
       "      <td>-73.973200</td>\n",
       "      <td>40.746367</td>\n",
       "      <td>1.744141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.572735</td>\n",
       "      <td>0.593518</td>\n",
       "      <td>0.055177</td>\n",
       "      <td>0.027119</td>\n",
       "      <td>0.058057</td>\n",
       "      <td>0.039485</td>\n",
       "      <td>1.363884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-75.454260</td>\n",
       "      <td>40.644590</td>\n",
       "      <td>-75.487345</td>\n",
       "      <td>40.560941</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-73.995657</td>\n",
       "      <td>40.728300</td>\n",
       "      <td>-73.991881</td>\n",
       "      <td>40.726121</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-73.986445</td>\n",
       "      <td>40.743842</td>\n",
       "      <td>-73.980107</td>\n",
       "      <td>40.745272</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-73.975086</td>\n",
       "      <td>40.759941</td>\n",
       "      <td>-73.957853</td>\n",
       "      <td>40.764050</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>112.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-73.776658</td>\n",
       "      <td>41.066758</td>\n",
       "      <td>-73.756890</td>\n",
       "      <td>41.076337</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fare_amount    hourofday    pickuplon    pickuplat   dropofflon  \\\n",
       "count  1024.000000  1024.000000  1024.000000  1024.000000  1024.000000   \n",
       "mean     11.642822     0.440430   -73.981624    40.745231   -73.973200   \n",
       "std       9.572735     0.593518     0.055177     0.027119     0.058057   \n",
       "min       2.500000     0.000000   -75.454260    40.644590   -75.487345   \n",
       "25%       6.100000     0.000000   -73.995657    40.728300   -73.991881   \n",
       "50%       8.900000     0.000000   -73.986445    40.743842   -73.980107   \n",
       "75%      13.500000     1.000000   -73.975086    40.759941   -73.957853   \n",
       "max     112.800000     2.000000   -73.776658    41.066758   -73.756890   \n",
       "\n",
       "        dropofflat   passengers  \n",
       "count  1024.000000  1024.000000  \n",
       "mean     40.746367     1.744141  \n",
       "std       0.039485     1.363884  \n",
       "min      40.560941     1.000000  \n",
       "25%      40.726121     1.000000  \n",
       "50%      40.745272     1.000000  \n",
       "75%      40.764050     2.000000  \n",
       "max      41.076337     6.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training dataset properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMNS = 'key,key_original,fare_amount,pickup_datetime,dayofweek,hourofday,pickuplon,pickuplat,dropofflon,dropofflat,passengers'.split(',')\n",
    "LABEL_COLUMN = 'fare_amount'\n",
    "KEY_FEATURE_COLUMN = 'key'\n",
    "DEFAULTS = [['nokey'], ['nokey'], [0.0], ['badDate'], ['Sun'], [0], [-74.0], [40.0], [-74.0], [40.7], [0.0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These are the raw input columns, and will be provided for prediction also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_COLUMNS = [\n",
    "    # Define features\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('dayofweek', vocabulary_list = ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat']),\n",
    "    tf.feature_column.categorical_column_with_identity('hourofday', num_buckets = 24),\n",
    "\n",
    "    # Numeric columns\n",
    "    tf.feature_column.numeric_column('pickuplat'),\n",
    "    tf.feature_column.numeric_column('pickuplon'),\n",
    "    tf.feature_column.numeric_column('dropofflat'),\n",
    "    tf.feature_column.numeric_column('dropofflon'),\n",
    "    tf.feature_column.numeric_column('passengers'),\n",
    "    \n",
    "    # Engineered features that are created in the input_fn\n",
    "    tf.feature_column.numeric_column('latdiff'),\n",
    "    tf.feature_column.numeric_column('londiff'),\n",
    "    tf.feature_column.numeric_column('euclidean')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_eval_metrics(labels, predictions):\n",
    "    pred_values = predictions['predictions']\n",
    "    return {\n",
    "        'rmse': tf.metrics.root_mean_squared_error(labels, pred_values)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_estimator(model_dir, nbuckets, hidden_units):\n",
    "    \"\"\"\n",
    "     Build an estimator starting from INPUT COLUMNS.\n",
    "     These include feature transformations and synthetic features.\n",
    "     The model is a wide-and-deep model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input columns\n",
    "    (dayofweek, hourofday, plat, plon, dlat, dlon, pcount, latdiff, londiff, euclidean) = INPUT_COLUMNS\n",
    "\n",
    "    # Bucketize the lats & lons\n",
    "    latbuckets = np.linspace(37.0, 45.0, nbuckets).tolist()\n",
    "    lonbuckets = np.linspace(-78.0, -70.0, nbuckets).tolist()\n",
    "    b_plat = tf.feature_column.bucketized_column(plat, latbuckets)\n",
    "    b_dlat = tf.feature_column.bucketized_column(dlat, latbuckets)\n",
    "    b_plon = tf.feature_column.bucketized_column(plon, lonbuckets)\n",
    "    b_dlon = tf.feature_column.bucketized_column(dlon, lonbuckets)\n",
    "\n",
    "    # Feature cross\n",
    "    ploc = tf.feature_column.crossed_column([b_plat, b_plon], nbuckets * nbuckets)\n",
    "    dloc = tf.feature_column.crossed_column([b_dlat, b_dlon], nbuckets * nbuckets)\n",
    "    pd_pair = tf.feature_column.crossed_column([ploc, dloc], nbuckets ** 4 )\n",
    "    day_hr =  tf.feature_column.crossed_column([dayofweek, hourofday], 24 * 7)\n",
    "\n",
    "    # Wide columns and deep columns.\n",
    "    wide_columns = [\n",
    "        # Feature crosses\n",
    "        dloc, ploc, pd_pair,\n",
    "        day_hr,\n",
    "\n",
    "        # Sparse columns\n",
    "        dayofweek, hourofday,\n",
    "\n",
    "        # Anything with a linear relationship\n",
    "        pcount \n",
    "    ]\n",
    "\n",
    "    deep_columns = [\n",
    "        # Embedding_column to \"group\" together ...\n",
    "        tf.feature_column.embedding_column(pd_pair, 10),\n",
    "        tf.feature_column.embedding_column(day_hr, 10),\n",
    "\n",
    "        # Numeric columns\n",
    "        plat, plon, dlat, dlon,\n",
    "        latdiff, londiff, euclidean\n",
    "    ]\n",
    "    \n",
    "    ## setting the checkpoint interval to be much lower for this task\n",
    "    run_config = tf.estimator.RunConfig(save_checkpoints_secs = 30, \n",
    "                                        keep_checkpoint_max = 3)\n",
    "    estimator = tf.estimator.DNNLinearCombinedRegressor(\n",
    "        model_dir = model_dir,\n",
    "        linear_feature_columns = wide_columns,\n",
    "        dnn_feature_columns = deep_columns,\n",
    "        dnn_hidden_units = hidden_units,\n",
    "        config = run_config)\n",
    "\n",
    "    # add extra evaluation metric for hyperparameter tuning\n",
    "    estimator = tf.contrib.estimator.add_metrics(estimator, add_eval_metrics)\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feature engineering function that will be used in the input and serving input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_engineered(features):\n",
    "    # this is how you can do feature engineering in TensorFlow\n",
    "    lat1 = features['pickuplat']\n",
    "    lat2 = features['dropofflat']\n",
    "    lon1 = features['pickuplon']\n",
    "    lon2 = features['dropofflon']\n",
    "    latdiff = (lat1 - lat2)\n",
    "    londiff = (lon1 - lon2)\n",
    "    \n",
    "    # set features for distance with sign that indicates direction\n",
    "    features['latdiff'] = latdiff\n",
    "    features['londiff'] = londiff\n",
    "    dist = tf.sqrt(latdiff * latdiff + londiff * londiff)\n",
    "    features['euclidean'] = dist\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create serving input function to be able to serve predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        # All the real-valued columns\n",
    "        column.name: tf.placeholder(tf.float32, [None]) for column in INPUT_COLUMNS[2:7]\n",
    "    }\n",
    "    feature_placeholders['dayofweek'] = tf.placeholder(tf.string, [None])\n",
    "    feature_placeholders['hourofday'] = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "    features = add_engineered(feature_placeholders.copy())\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input function to load data into datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filename, mode, batch_size = 512):\n",
    "    def _input_fn():\n",
    "        def decode_csv(value_column):\n",
    "            columns = tf.decode_csv(value_column, record_defaults = DEFAULTS)\n",
    "            features = dict(zip(CSV_COLUMNS, columns))\n",
    "            label = features.pop(LABEL_COLUMN)\n",
    "            return add_engineered(features), label\n",
    "        \n",
    "        # Create list of files that match pattern\n",
    "        file_list = tf.gfile.Glob(filename)\n",
    "\n",
    "        # Create dataset from file list\n",
    "        dataset = tf.data.TextLineDataset(file_list).skip(1).map(decode_csv)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None # indefinitely\n",
    "            dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "        else:\n",
    "            num_epochs = 1 # end-of-input after this\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "        batch_features, batch_labels = dataset.make_one_shot_iterator().get_next()\n",
    "        return batch_features, batch_labels\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create estimator train and evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(args):\n",
    "    estimator = build_estimator(args['output_dir'], args['nbuckets'], args['hidden_units'].split(' '))\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn = read_dataset(\n",
    "            filename = args['train_data_paths'],\n",
    "            mode = tf.estimator.ModeKeys.TRAIN,\n",
    "            batch_size = args['train_batch_size']),\n",
    "        max_steps = args['train_steps'])\n",
    "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn = read_dataset(\n",
    "            filename = args['eval_data_paths'],\n",
    "            mode = tf.estimator.ModeKeys.EVAL,\n",
    "            batch_size = args['eval_batch_size']),\n",
    "        steps = 100,\n",
    "        exporters = exporter)\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\mistr\\\\source\\\\repos\\\\rrmistry\\\\kaggle\\\\NY_Taxi_Cab\\\\ML_Model', '_log_step_count_steps': 100, '_service': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_is_chief': True, '_save_checkpoints_secs': 30, '_keep_checkpoint_max': 3, '_task_id': 0, '_tf_random_seed': None, '_train_distribute': None, '_num_ps_replicas': 0, '_device_fn': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000015F96251748>, '_num_worker_replicas': 1, '_master': '', '_session_config': None, '_task_type': 'worker'}\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\mistr\\\\source\\\\repos\\\\rrmistry\\\\kaggle\\\\NY_Taxi_Cab\\\\ML_Model', '_log_step_count_steps': 100, '_service': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_is_chief': True, '_save_checkpoints_secs': 30, '_keep_checkpoint_max': 3, '_task_id': 0, '_tf_random_seed': None, '_train_distribute': None, '_num_ps_replicas': 0, '_device_fn': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000015F96246048>, '_num_worker_replicas': 1, '_master': '', '_session_config': None, '_task_type': 'worker'}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 30.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 101305.63, step = 0\n",
      "INFO:tensorflow:global_step/sec: 11.2702\n",
      "INFO:tensorflow:loss = 43685.773, step = 100 (8.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9919\n",
      "INFO:tensorflow:loss = 51152.953, step = 200 (7.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.247\n",
      "INFO:tensorflow:loss = 59367.953, step = 300 (7.020 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 377 into C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-16-02:52:35\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt-377\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-16-02:52:43\n",
      "INFO:tensorflow:Saving dict for global step 377: average_loss = 81.56009, global_step = 377, label/mean = 11.595333, loss = 41758.766, prediction/mean = 11.434464, rmse = 9.031062\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 377: C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt-377\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'pickuplat': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'dayofweek': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=string>, 'pickuplon': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'passengers': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float32>, 'dropofflat': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float32>, 'dropofflon': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'hourofday': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=int32>}\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'pickuplat': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'dayofweek': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=string>, 'pickuplon': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'passengers': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float32>, 'dropofflat': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float32>, 'dropofflon': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'hourofday': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=int32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt-377\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\export\\exporter\\temp-b'1537066364'\\saved_model.pb\n",
      "INFO:tensorflow:global_step/sec: 5.20156\n",
      "INFO:tensorflow:loss = 34001.902, step = 400 (19.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6456\n",
      "INFO:tensorflow:loss = 46527.223, step = 500 (6.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8053\n",
      "INFO:tensorflow:loss = 49806.617, step = 600 (6.328 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 647 into C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 13.7174\n",
      "INFO:tensorflow:loss = 48321.46, step = 700 (7.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1203\n",
      "INFO:tensorflow:loss = 49827.992, step = 800 (7.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4321\n",
      "INFO:tensorflow:loss = 33280.504, step = 900 (6.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8781\n",
      "INFO:tensorflow:loss = 40891.004, step = 1000 (6.298 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1092 into C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.9187\n",
      "INFO:tensorflow:loss = 52766.832, step = 1100 (6.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5231\n",
      "INFO:tensorflow:loss = 35411.32, step = 1200 (6.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6007\n",
      "INFO:tensorflow:loss = 50220.098, step = 1300 (6.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2157\n",
      "INFO:tensorflow:loss = 37043.902, step = 1400 (6.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9185\n",
      "INFO:tensorflow:loss = 28396.703, step = 1500 (6.282 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1548 into C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.4363\n",
      "INFO:tensorflow:loss = 25348.926, step = 1600 (6.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0989\n",
      "INFO:tensorflow:loss = 48218.76, step = 1700 (6.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4653\n",
      "INFO:tensorflow:loss = 37770.957, step = 1800 (6.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1883\n",
      "INFO:tensorflow:loss = 26971.762, step = 1900 (6.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6829\n",
      "INFO:tensorflow:loss = 34332.395, step = 2000 (6.377 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2003 into C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 13.7323\n",
      "INFO:tensorflow:loss = 37262.105, step = 2100 (7.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5603\n",
      "INFO:tensorflow:loss = 45862.25, step = 2200 (6.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9254\n",
      "INFO:tensorflow:loss = 31499.559, step = 2300 (6.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8302\n",
      "INFO:tensorflow:loss = 48031.004, step = 2400 (6.743 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2439 into C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.4676\n",
      "INFO:tensorflow:loss = 42913.484, step = 2500 (6.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2045\n",
      "INFO:tensorflow:loss = 49715.754, step = 2600 (6.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8588\n",
      "INFO:tensorflow:loss = 65555.45, step = 2700 (6.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4367\n",
      "INFO:tensorflow:loss = 61375.676, step = 2800 (6.478 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2891 into C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.5642\n",
      "INFO:tensorflow:loss = 42149.22, step = 2900 (6.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.2167\n",
      "INFO:tensorflow:loss = 70373.125, step = 3000 (7.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6049\n",
      "INFO:tensorflow:loss = 44310.9, step = 3100 (6.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1791\n",
      "INFO:tensorflow:loss = 63292.42, step = 3200 (6.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1676\n",
      "INFO:tensorflow:loss = 43638.33, step = 3300 (6.593 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3331 into C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 13.624\n",
      "INFO:tensorflow:loss = 47343.527, step = 3400 (7.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8332\n",
      "INFO:tensorflow:loss = 57744.207, step = 3500 (7.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3844\n",
      "INFO:tensorflow:loss = 43640.547, step = 3600 (6.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1217\n",
      "INFO:tensorflow:loss = 49088.758, step = 3700 (6.614 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3762 into C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.8017\n",
      "INFO:tensorflow:loss = 43882.137, step = 3800 (6.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9606\n",
      "INFO:tensorflow:loss = 76766.19, step = 3900 (7.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4802\n",
      "INFO:tensorflow:loss = 62025.5, step = 4000 (6.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2091\n",
      "INFO:tensorflow:loss = 37786.305, step = 4100 (6.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0871\n",
      "INFO:tensorflow:loss = 46900.668, step = 4200 (6.217 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4206 into C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 14.8386\n",
      "INFO:tensorflow:loss = 36284.695, step = 4300 (6.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0128\n",
      "INFO:tensorflow:loss = 47614.367, step = 4400 (6.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8898\n",
      "INFO:tensorflow:loss = 41210.273, step = 4500 (6.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9701\n",
      "INFO:tensorflow:loss = 42224.887, step = 4600 (6.680 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4654 into C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 13.7741\n",
      "INFO:tensorflow:loss = 51209.46, step = 4700 (7.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5593\n",
      "INFO:tensorflow:loss = 42342.3, step = 4800 (7.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.2511\n",
      "INFO:tensorflow:loss = 43215.355, step = 4900 (7.017 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-16-02:58:00\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-16-02:58:07\n",
      "INFO:tensorflow:Saving dict for global step 5000: average_loss = 81.31924, global_step = 5000, label/mean = 11.595333, loss = 41635.45, prediction/mean = 11.378033, rmse = 9.017718\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt-5000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'pickuplat': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'dayofweek': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=string>, 'pickuplon': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'passengers': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float32>, 'dropofflat': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float32>, 'dropofflon': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'hourofday': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=int32>}\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'pickuplat': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'dayofweek': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=string>, 'pickuplon': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'passengers': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float32>, 'dropofflat': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float32>, 'dropofflon': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'hourofday': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=int32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\model.ckpt-5000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model\\export\\exporter\\temp-b'1537066687'\\saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 65257.266.\n"
     ]
    }
   ],
   "source": [
    "# OUTPUTDIR = os.path.join(BASE_PATH, r'../ML_Model/')\n",
    "OUTPUTDIR = r'C:\\Users\\mistr\\source\\repos\\rrmistry\\kaggle\\NY_Taxi_Cab\\ML_Model'\n",
    "\n",
    "if os.path.exists(OUTPUTDIR):\n",
    "    shutil.rmtree(OUTPUTDIR)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    arguments = {\n",
    "        \"output_dir\": OUTPUTDIR,\n",
    "        \"train_data_paths\": os.path.join(BASE_PATH, r'..\\input\\train_split\\train-*.csv'),\n",
    "        \"eval_data_paths\": os.path.join(BASE_PATH, r'..\\input\\train_split\\valid-*.csv'),\n",
    "        \"train_batch_size\": 512,\n",
    "        \"eval_batch_size\": 512,\n",
    "        \"train_steps\": 5000,\n",
    "        \"eval_steps\": 10,\n",
    "        \"nbuckets\": 10,\n",
    "        \"hidden_units\": \"128 32 4\",\n",
    "        \"eval_delay_secs\": 10,\n",
    "        \"min_eval_frequency\": 1,\n",
    "        \"format\": \"csv\"\n",
    "    }\n",
    "    \n",
    "    # Run the training job:\n",
    "    try:\n",
    "        train_and_evaluate(arguments)\n",
    "    except:\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
